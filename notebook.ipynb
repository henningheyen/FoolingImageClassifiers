{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxy13bm08xgh"
      },
      "source": [
        "# Fooling Image Classifiers\n",
        "\n",
        "  - **Author**: Henning Heyen\n",
        "  - **Date**: 05/04/2023\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to this notebook!\n",
        "\n",
        "The goal of this project is to show how state-of-the-art image classifiers behave when the\n",
        "input images are **out of distribution**.\n",
        "\n",
        "We use common Imagenet pre-trained models to pass\n",
        "the images through. We then build an ensemble model and measure its prediction uncertainty.Then we actively try to fool one of the models using different perturbated images and investigate their saliency maps.\n",
        "\n",
        "Please find an in depth **report** on this project in the [GitHub repository](https://github.com/henningheyen/FoolingImageClassifiers).\n",
        "\n",
        "To run this notebook please use Google Colab as all libraries (especially TF Keras) are preinstalled there."
      ],
      "metadata": {
        "id": "tmBStJBJCh4e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDYFM3A588Ot"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "[1 Collecting a test set with epistemic uncertainty and passing it through image classifiers](#1)\n",
        "\n",
        "[2 Building an uncertainty quantification ensemble](#2)\n",
        "\n",
        "[3 Fooling one of the models](#3)\n",
        "\n",
        "[4 Analysing saliency maps for the images](#4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFqWj_mP9YlR"
      },
      "source": [
        "<a id='1'></a>\n",
        "# 1 Collecting a test set with epistemic uncertainty and passing it through image classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-cbh5l59Rsl"
      },
      "outputs": [],
      "source": [
        "#@title mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7duVZ5ttK64g"
      },
      "outputs": [],
      "source": [
        "#@title helper methods\n",
        "\n",
        "# importing an image, change the path if necessary\n",
        "def path(image_name):\n",
        "  data_path = '/content/drive/MyDrive/images'\n",
        "  return os.path.join(data_path, image_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjcDY7BPS3Bj"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import PIL.Image\n",
        "from matplotlib import pylab as P\n",
        "import os, sys\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess_input\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess_input\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess_input\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CviI8XdsbnOq"
      },
      "outputs": [],
      "source": [
        "# list of images\n",
        "umbrellas = [load_img(path(f'umbrella{i}.jpeg'), keep_aspect_ratio=True) for i in range(0,6)]\n",
        "\n",
        "# plotting images\n",
        "f, axarr = plt.subplots(2,3, figsize=(20, 10))\n",
        "axarr[0,0].imshow(umbrellas[0])\n",
        "axarr[0,0].set_title('umbrella0')\n",
        "axarr[0,0].axis('off')\n",
        "axarr[0,1].imshow(umbrellas[1])\n",
        "axarr[0,1].set_title('umbrella1')\n",
        "axarr[0,1].axis('off')\n",
        "axarr[0,2].imshow(umbrellas[2])\n",
        "axarr[0,2].set_title('umbrella2')\n",
        "axarr[0,2].axis('off')\n",
        "axarr[1,0].imshow(umbrellas[3])\n",
        "axarr[1,0].set_title('umbrella3')\n",
        "axarr[1,0].axis('off')\n",
        "axarr[1,1].imshow(umbrellas[4])\n",
        "axarr[1,1].set_title('umbrella4')\n",
        "axarr[1,1].axis('off')\n",
        "axarr[1,2].imshow(umbrellas[5])\n",
        "axarr[1,2].set_title('umbrella5')\n",
        "axarr[1,2].axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvktNGYqTNBI"
      },
      "outputs": [],
      "source": [
        "# keras pretrained models\n",
        "vgg16 = VGG16(weights='imagenet')\n",
        "resnet50 = ResNet50(weights='imagenet')\n",
        "inceptionv3 = InceptionV3(weights='imagenet')\n",
        "xception = Xception(weights='imagenet')\n",
        "mobilenetv2 = MobileNetV2(weights='imagenet')\n",
        "\n",
        "models = [\n",
        "    vgg16,\n",
        "    resnet50,\n",
        "    inceptionv3,\n",
        "    xception,\n",
        "    mobilenetv2,\n",
        "]\n",
        "\n",
        "# preprocessing methods for each classifier\n",
        "preprocess_methods = [\n",
        "    vgg_preprocess_input,\n",
        "    resnet_preprocess_input,\n",
        "    inception_preprocess_input,\n",
        "    xception_preprocess_input,\n",
        "    mobilenet_preprocess_input,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYgjOj6kjH5k"
      },
      "outputs": [],
      "source": [
        "# Overview on models\n",
        "data = {\n",
        "    'model': ['vgg16', 'resnet50', 'inception_v3', 'xception', 'mobilenetv2'],\n",
        "    'top 1 accuracy': [0.713, 0.749, 0.779, 0.790, 0.713],\n",
        "    'top 5 accuracy': [0.901, 0.921, 0.938, 0.949, 0.901],\n",
        "    'parameters': ['138.4M', '25.6M', '23.9M', '22.9M', '3.5M'],\n",
        "    'depth': [16, 50, 189, 81, 105],\n",
        "    'special characteristics': ['simple and uniform architecture',\n",
        "                                 'residual blocks, state of the art',\n",
        "                                 'multiple parallel convolutional operations',\n",
        "                                 'depthwise separable convolutions',\n",
        "                                 'efficient on mobile devices, fewer parameters']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jCkyzfQSscN"
      },
      "outputs": [],
      "source": [
        "def predict_image(model, preprocess, image_name, top_k=3):\n",
        "  '''\n",
        "    @param:\n",
        "      model: pretrained classifier\n",
        "      preprocess: preprocess method associated with the model\n",
        "      image_name: string of the image like to be imported, see path() helper function\n",
        "      top_k: k top predictions from imagenet\n",
        "\n",
        "    @return:\n",
        "      list of top k predictions with certainty\n",
        "  '''\n",
        "\n",
        "  # loading and formatting image\n",
        "  input_shape = model.input_shape[1:3]\n",
        "  img = load_img(path(image_name), target_size=input_shape)\n",
        "  img_arr = img_to_array(img)\n",
        "  img_arr = np.expand_dims(img_arr, axis=0)\n",
        "\n",
        "  # preprocess and predict image\n",
        "  processed_img = preprocess(img_arr.copy())\n",
        "  preds = model.predict(processed_img, verbose=0)\n",
        "  top_preds = decode_predictions(preds, top=top_k)[0]\n",
        "\n",
        "  return top_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bacTrlPMXkfn"
      },
      "outputs": [],
      "source": [
        "all_top_preds = []\n",
        "\n",
        "# predincting for all models on each image\n",
        "for j in range(0,6):\n",
        "  print('\\n', '-'*50, f'umbrella{j}', '-'*50)\n",
        "  for i, model in enumerate(models):\n",
        "    image_name = f'umbrella{j}.jpeg'\n",
        "    preprocess = preprocess_methods[i]\n",
        "    top_preds = predict_image(model=model, preprocess=preprocess, image_name=image_name)\n",
        "    all_top_preds.append([(top_preds[i][1], round(top_preds[i][2],3)) for i in range(len(top_preds))])\n",
        "    print(f'Top 3 predictions for {model.name}: {top_preds}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5E6Y2Ct_sG1"
      },
      "outputs": [],
      "source": [
        "# Creating a dataframe with the results\n",
        "\n",
        "# Define the list of models and images\n",
        "model_names = [\"vgg16\", \"resnet50\", \"inception_v3\", \"xception\", \"mobilenetv2\"]\n",
        "image_names = [\"umbrella0\", \"umbrella1\", \"umbrella2\", \"umbrella3\", \"umbrella4\", \"umbrella5\"]\n",
        "\n",
        "# Initialize empty lists for each column\n",
        "model_names_list = []\n",
        "image_names_list = []\n",
        "prediction_list = []\n",
        "\n",
        "# Iterate over the models and images\n",
        "for i,image_name in enumerate(image_names):\n",
        "  for j,model_name in enumerate(model_names):\n",
        "\n",
        "    # Append the values to the corresponding lists\n",
        "    model_names_list.append(model_name)\n",
        "    image_names_list.append(image_name)\n",
        "    prediction_list.append(all_top_preds[i*5+j])\n",
        "\n",
        "# Create the dataframe\n",
        "df = pd.DataFrame({\n",
        "    \"model\": model_names_list,\n",
        "    \"image\": image_names_list,\n",
        "    \"Top 3 predictions\": prediction_list,\n",
        "})\n",
        "\n",
        "\n",
        "# showing the full entries\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "df.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0xpHQVwx7aa"
      },
      "outputs": [],
      "source": [
        "# Computing all models accuracies on the 6 test images\n",
        "\n",
        "accuracies = []\n",
        "idx = [0,5,10,15,20,25]\n",
        "\n",
        "# testing for correct prediction\n",
        "for i in range(5):\n",
        "  accuracies.append(sum([all_top_preds[i+j][0][0]=='umbrella' for j in idx])/6)\n",
        "\n",
        "# creating dataframe\n",
        "df_acc = pd.DataFrame({'model':model_names, 'accuracy':accuracies})\n",
        "df_acc.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzxJOmfP_Jaj"
      },
      "source": [
        "<a id='2'></a>\n",
        "# 2 Building an uncertainty quantification ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIisO6pxOLU_"
      },
      "outputs": [],
      "source": [
        "# Using all five models and average the predictions:\n",
        "def predict_avg(image_name, top_k=1):\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    # predicting on each model and saving the results\n",
        "    for model, preprocess in zip(models, preprocess_methods):\n",
        "      # loading and formatting image\n",
        "      input_shape = model.input_shape[1:3]\n",
        "      img = image.load_img(path(image_name), target_size=input_shape)\n",
        "      img_arr = image.img_to_array(img)\n",
        "      img_arr = np.expand_dims(img_arr, axis=0)\n",
        "\n",
        "      # preprocess and predict image\n",
        "      processed_img = preprocess(img_arr.copy())\n",
        "      pred = model.predict(processed_img, verbose=0)[0]\n",
        "      preds.append(pred)\n",
        "\n",
        "    # aggregarting the predictions by averaging\n",
        "    avg_pred = np.mean(preds, axis=0).reshape(1,1000)\n",
        "\n",
        "    #decoding the average prediction\n",
        "    top_preds = decode_predictions(avg_pred, top=top_k)[0]\n",
        "\n",
        "    return top_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6RwL9Y0RN92"
      },
      "outputs": [],
      "source": [
        "all_top_ens_preds = []\n",
        "\n",
        "# using the ensemble predicting on each image\n",
        "for j in range(0,6):\n",
        "  print('\\n', '-'*50, f'umbrella{j}', '-'*50)\n",
        "  image_name = f'umbrella{j}.jpeg'\n",
        "  top_preds = predict_avg(image_name)\n",
        "  all_top_ens_preds.append([(top_preds[i][1], round(top_preds[i][2],3)) for i in range(len(top_preds))])\n",
        "  print(f'Top 1 predictions for ensemble: {top_preds}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LCd2Xi_bo-G"
      },
      "outputs": [],
      "source": [
        "df_ensemble = pd.DataFrame({'image':image_names,\n",
        "                            'prediction': [all_top_ens_preds[i][0][0] for i in range(6)],\n",
        "                            'max probability': [all_top_ens_preds[i][0][1] for i in range(6)]})\n",
        "df_ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCdENmPHd0MW"
      },
      "outputs": [],
      "source": [
        "# Extending the accuracy table by the ensemble\n",
        "new_row = pd.DataFrame({'model':['ensemble'], 'accuracy':[sum([all_top_ens_preds[i][0][0]=='umbrella' for i in range(6)])/6]})\n",
        "df_acc = pd.concat([df_acc, new_row], axis=0, ignore_index=True)\n",
        "df_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2brst725_Mme"
      },
      "source": [
        "<a id='3'></a>\n",
        "# 3 Fooling one of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp_73Hn950zC"
      },
      "outputs": [],
      "source": [
        "# helper method to plot an image\n",
        "def plot(image_name):\n",
        "  img = load_img(path(f'{image_name}.jpeg'), keep_aspect_ratio=True)\n",
        "  plt.figure(figsize=(8,6))\n",
        "  plt.imshow(img)\n",
        "  plt.title(image_name)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZMVFKchhmlx"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Creating some noise images:\n",
        "\n",
        " For reproducability purposes this code is commented out\n",
        " since the noise added is random and might therefore give\n",
        " different predictions.\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from skimage.util import random_noise\n",
        "\n",
        "\n",
        "for im in ['flamingo','zebra']:\n",
        "\n",
        "  # Load the image\n",
        "  img = cv2.imread(path(f'{im}0.jpeg'))\n",
        "\n",
        "  # Adding salt-and-pepper noise to the image.\n",
        "  noise_img = random_noise(img, mode='s&p', amount=0.3)\n",
        "  noise_img = np.array(255*noise_img, dtype = 'uint8')\n",
        "\n",
        "  # save the image\n",
        "  # cv2_imshow(noise_img) # uncomment to show image\n",
        "  cv2.imwrite(path(f'{im}14.jpeg'), noise_img)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxQ2r9CS7W4E"
      },
      "outputs": [],
      "source": [
        "# Predicting on all zebra images and saving the results\n",
        "preds_list_zebra = []\n",
        "probs_list_zebra = []\n",
        "\n",
        "for i in range(15):\n",
        "  preds = predict_image(xception, xception_preprocess_input, f'zebra{i}.jpeg')\n",
        "  preds_list_zebra.append(preds[0][1])\n",
        "  probs_list_zebra.append(round(preds[0][2],3))\n",
        "  print(100*'-', f'\\n Top 3 predictions for zebra{i}: {preds}')\n",
        "  plot(f'zebra{i}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEbWjpVIYkBq"
      },
      "outputs": [],
      "source": [
        "# Predicting on all flamingo images and saving the results\n",
        "preds_list_flamingo = []\n",
        "probs_list_flamingo = []\n",
        "\n",
        "for i in range(15):\n",
        "  preds = predict_image(xception, xception_preprocess_input, f'flamingo{i}.jpeg')\n",
        "  preds_list_flamingo.append(preds[0][1])\n",
        "  probs_list_flamingo.append(round(preds[0][2],3))\n",
        "  print(100*'-', f'\\n Top 3 predictions for flamingo{i}: {preds}')\n",
        "  plot(f'flamingo{i}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn6kaAYTuWYp"
      },
      "outputs": [],
      "source": [
        "# table on zebra results\n",
        "df_zebra = pd.DataFrame({'image': [f'zebra{i}' for i in range(15)],\n",
        "                         'prediction': preds_list_zebra,\n",
        "                         'probability': probs_list_zebra})\n",
        "\n",
        "df_zebra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t8asyXUu9p3"
      },
      "outputs": [],
      "source": [
        "# table on flamingo results\n",
        "df_flamingo = pd.DataFrame({'image': [f'flamingo{i}' for i in range(15)],\n",
        "                         'prediction': preds_list_flamingo,\n",
        "                         'probability': probs_list_flamingo})\n",
        "\n",
        "df_flamingo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw7kzV15ckN6"
      },
      "outputs": [],
      "source": [
        "# Calculating accuracies on all fooling images (15 zebras, 15 flamingos)\n",
        "accuracy_zebra = []\n",
        "accuracy_flamingo = []\n",
        "\n",
        "for model,preprocess in zip(models,preprocess_methods):\n",
        "\n",
        "  preds_list_flamingo = []\n",
        "  probs_list_flamingo = []\n",
        "\n",
        "  for i in range(15):\n",
        "    preds = predict_image(model, preprocess, f'flamingo{i}.jpeg')\n",
        "    preds_list_flamingo.append(preds[0][1])\n",
        "    probs_list_flamingo.append(round(preds[0][2],3))\n",
        "\n",
        "  # calculating and appending the results\n",
        "  accuracy_zebra.append(sum([preds_list_zebra[i]=='zebra' for i in range(15)])/15)\n",
        "  accuracy_flamingo.append(round(sum([preds_list_flamingo[i]=='flamingo' for i in range(15)])/15,3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qyo7HyRnbjIm"
      },
      "outputs": [],
      "source": [
        "# table on accuracies for fooling images\n",
        "df_acc_fool = pd.DataFrame({'model': model_names,\n",
        "                            'accuracy zebra': accuracy_zebra,\n",
        "                            'accuracy flamingo': accuracy_flamingo,})\n",
        "\n",
        "df_acc_fool\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HroJsQYh_POs"
      },
      "source": [
        "<a id='4'></a>\n",
        "# 4 Analysing saliency maps for the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SAC380I-8pmt"
      },
      "outputs": [],
      "source": [
        "#@title load saliency module\n",
        "\n",
        "# Install PAIR Saliency Library\n",
        "!pip install saliency\n",
        "# From PAIR saliency repository.\n",
        "import saliency.core as saliency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QB6m3bH3qmK"
      },
      "outputs": [],
      "source": [
        "#@title helper methods\n",
        "def LoadImage(file_path):\n",
        "  im = PIL.Image.open(file_path)\n",
        "  im = im.resize((299,299))\n",
        "  im = np.asarray(im)\n",
        "  return im\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CsNibttWuD2"
      },
      "outputs": [],
      "source": [
        "# saving all image names in one list\n",
        "umbrella_names = [f'umbrella{i}' for i in range(6)]\n",
        "zebra_names = [f'zebra{i}' for i in range(15)]\n",
        "flamingo_names = [f'flamingo{i}' for i in range(15)]\n",
        "\n",
        "all_image_names = [*umbrella_names, *zebra_names, *flamingo_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFxJjmTrj6Ys"
      },
      "outputs": [],
      "source": [
        "# From Lab 4, call_model_function to create saliency maps, model was replaced by model_xception\n",
        "class_idx_str = 'class_idx_str'\n",
        "def call_model_function(images, call_model_args=None, expected_keys=None):\n",
        "    target_class_idx =  call_model_args[class_idx_str]\n",
        "    images = tf.convert_to_tensor(images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        if expected_keys==[saliency.base.INPUT_OUTPUT_GRADIENTS]:\n",
        "            tape.watch(images)\n",
        "            output_layer = model_xception(images)\n",
        "            output_layer = output_layer[:,target_class_idx]\n",
        "            gradients = np.array(tape.gradient(output_layer, images))\n",
        "            return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
        "        else:\n",
        "            conv_layer, output_layer = model_xception(images)\n",
        "            gradients = np.array(tape.gradient(output_layer, conv_layer))\n",
        "            return {saliency.base.CONVOLUTION_LAYER_VALUES: conv_layer,\n",
        "                    saliency.base.CONVOLUTION_OUTPUT_GRADIENTS: gradients}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T21hYrvIhqwg"
      },
      "outputs": [],
      "source": [
        "# importing the imagenet labels, change path if necessary\n",
        "import json\n",
        "\n",
        "# Change path if necessary\n",
        "with open('/content/drive/MyDrive/imagenet_class_index.json', 'r') as f:\n",
        "    class_idx = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OSxCTZE5w9c"
      },
      "outputs": [],
      "source": [
        "# Similar to Lab 4 creating a keras model based on the pretrained xception\n",
        "model_xception = tf.keras.models.Model([xception.inputs], [xception.output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y42jhe4JfU4d"
      },
      "outputs": [],
      "source": [
        "# Creating SmoothGrad Saliency maps for all images using the xception model\n",
        "for image_name in all_image_names:\n",
        "  # Load the image\n",
        "  im_orig = LoadImage(path(f'{image_name}.jpeg'))\n",
        "\n",
        "  # remove potential 4th channel to retrieve RBG format\n",
        "  if im_orig.shape[-1] > 3:\n",
        "    im_orig = im_orig[:, :, :3]\n",
        "\n",
        "  #preprocess image\n",
        "  im = xception_preprocess_input(im_orig)\n",
        "\n",
        "  # predict image using the moethod from task 1\n",
        "  preds = predict_image(xception, xception_preprocess_input, image_name=f'{image_name}.jpeg')\n",
        "  # extracting the class index\n",
        "  prediction_class = int(list(class_idx.keys())[list(class_idx.values()).index(list(preds[0][0:2]))])\n",
        "  # create argument for GetSmoothedMask\n",
        "  call_model_args = {class_idx_str: prediction_class}\n",
        "\n",
        "  #print prediction and max probability\n",
        "  print(100*'-', f\"\\n Prediction for {image_name}: \", preds[0][1:3])\n",
        "\n",
        "  # Construct the saliency object\n",
        "  gradient_saliency = saliency.GradientSaliency()\n",
        "\n",
        "  # Compute SmoothGrad mask.\n",
        "  smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im, call_model_function, call_model_args)\n",
        "\n",
        "  # Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
        "  smoothgrad_mask_grayscale = saliency.VisualizeImageGrayscale(smoothgrad_mask_3d)\n",
        "\n",
        "  # Figure\n",
        "  f = plt.figure(figsize=(10,5))\n",
        "  f.add_subplot(1,2, 1)\n",
        "\n",
        "  P.axis('off')\n",
        "  P.imshow(im_orig)\n",
        "  P.title(image_name)\n",
        "  f.add_subplot(1,2, 2)\n",
        "\n",
        "  P.axis('off')\n",
        "  P.imshow(smoothgrad_mask_grayscale, cmap=P.cm.gray, vmin=0, vmax=1)\n",
        "  P.title(f'SmoothGrad {image_name}')\n",
        "  plt.subplots_adjust(wspace=0, hspace=0)\n",
        "  P.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}